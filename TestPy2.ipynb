{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 63), ('the', 52), ('to', 36), ('i', 32), ('of', 28), ('that', 27), ('in', 27), ('my', 26), ('for', 22), ('not', 21)]\n"
     ]
    }
   ],
   "source": [
    "def get_tokens():\n",
    "   with open('Tests/Tests/shakes1.txt','r') as shakes:\n",
    "        text = shakes.read()\n",
    "        lowers = text.lower()\n",
    "        \n",
    "        #remove the punctuation using the character deletion step of translate\n",
    "        no_punctuation = lowers.translate(None, string.punctuation)\n",
    "        tokens = nltk.word_tokenize(no_punctuation)\n",
    "        return tokens\n",
    "    \n",
    "tokens = get_tokens()\n",
    "count = Counter(tokens)\n",
    "print count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('thy', 11), ('love', 9), ('go', 7), ('thee', 7), ('master', 6), ('thou', 6), ('much', 6), ('daughter', 5), ('would', 5), ('service', 5), ('gentle', 5), ('well', 5), ('world', 5), ('like', 5), ('old', 5), ('father', 4), ('lord', 4), ('never', 4), ('let', 4), ('none', 4), ('may', 4), ('better', 4), ('good', 4), ('one', 4), ('nature', 4), ('upon', 4), ('tis', 4), ('virginity', 4), ('shall', 4), ('hath', 3), ('young', 3), ('heaven', 3), ('along', 3), ('company', 3), ('must', 3), ('still', 3), ('man', 3), ('keep', 3), ('think', 3), ('part', 3), ('quoth', 3), ('fair', 3), ('sweet', 3), ('doth', 3), ('thus', 3), ('yet', 3), ('seek', 3), ('kings', 3), ('virtues', 3), ('duke', 3), ('made', 3), ('together', 3), ('poor', 3), ('age', 3), ('late', 2), ('virtuous', 2), ('worse', 2), ('every', 2), ('die', 2), ('leave', 2), ('gentlewoman', 2), ('graces', 2), ('ten', 2), ('wherefore', 2), ('favour', 2), ('praise', 2), ('strong', 2), ('great', 2), ('makes', 2), ('eye', 2), ('sake', 2), ('therefore', 2), ('sanctified', 2), ('native', 2), ('sir', 2), ('wrong', 2), ('blood', 2), ('light', 2), ('indeed', 2), ('years', 2), ('went', 2), ('gainst', 2), ('living', 2), ('feed', 2), ('fourscore', 2), ('pains', 2), ('excellent', 2), ('grace', 2), ('bertram', 2), ('see', 2), ('fashion', 2), ('lie', 2), ('take', 2), ('though', 2), ('bright', 2), ('knowledge', 2), ('bear', 2), ('seventeen', 2), ('honesty', 2), ('youth', 2)]\n"
     ]
    }
   ],
   "source": [
    "tokens = get_tokens()\n",
    "filtered = [w for w in tokens if not w in stopwords.words('english')]\n",
    "count = Counter(filtered)\n",
    "print count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'thi', 11), ('love', 10), ('go', 7), ('thee', 7), ('master', 7), ('good', 6), ('thou', 6), ('much', 6), ('like', 6), ('father', 5), (u'servic', 5), (u'natur', 5), ('daughter', 5), ('would', 5), (u'live', 5), (u'gentl', 5), ('well', 5), ('world', 5), ('old', 5), (u'virgin', 5), (u'ti', 4), ('lord', 4), ('never', 4), ('let', 4), ('none', 4), ('may', 4), (u'late', 4), ('one', 4), ('part', 4), ('grace', 4), (u'king', 4), (u'come', 4), ('better', 4), (u'virtu', 4), (u'make', 4), ('upon', 4), ('shall', 4), ('hath', 3), ('young', 3), ('heaven', 3), ('die', 3), (u'fortun', 3), ('eye', 3), (u'compani', 3), ('must', 3), (u'give', 3), ('still', 3), ('year', 3), ('keep', 3), ('think', 3), (u'feed', 3), ('man', 3), ('friend', 3), ('bertram', 3), ('seek', 3), (u'traitor', 3), (u'bear', 3), ('fair', 3), ('youth', 3), ('sweet', 3), ('along', 3), (u'life', 3), (u'togeth', 3), ('doth', 3), (u'sanctifi', 3), (u'thu', 3), ('yet', 3), ('quoth', 3), ('duke', 3), ('made', 3), ('poor', 3), ('age', 3), ('lack', 2), (u'everi', 2), ('gentlewoman', 2), ('ten', 2), ('favour', 2), (u'fourscor', 2), ('strong', 2), ('great', 2), ('sake', 2), (u'peopl', 2), (u'wors', 2), (u'heart', 2), ('sir', 2), (u'comfort', 2), ('wrong', 2), ('blood', 2), ('light', 2), (u'plagu', 2), (u'therefor', 2), ('went', 2), (u'confess', 2), (u'thing', 2), (u'carri', 2), (u'miss', 2), ('see', 2), ('fashion', 2), (u'manner', 2), ('lie', 2)]\n"
     ]
    }
   ],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = stem_tokens(filtered, stemmer)\n",
    "count = Counter(stemmed)\n",
    "print count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Tests/Tests'\n",
    "token_dict = {}\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_path = subdir + os.path.sep + file\n",
    "        shakes = open(file_path, 'r')\n",
    "        text = shakes.read()\n",
    "        lowers = text.lower()\n",
    "        no_punctuation = lowers.translate(None, string.punctuation)\n",
    "        token_dict[file] = no_punctuation\n",
    "        \n",
    "#this can take some time\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "tfs = tfidf.fit_transform(token_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 425)\t0.5773502691896258\n",
      "  (0, 226)\t0.5773502691896258\n",
      "  (0, 193)\t0.5773502691896258\n"
     ]
    }
   ],
   "source": [
    "str = 'this sentence has unseen text such as computer but also king lord juliet'\n",
    "response = tfidf.transform(['this is new str and hope to find the king and juliet'])\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thi  -  0.5773502691896258\n",
      "lord  -  0.5773502691896258\n",
      "king  -  0.5773502691896258\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "for col in response.nonzero()[1]:\n",
    "    print feature_names[col], ' - ', response[0, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ngram\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/84/707fdecbe63e67345db200a86274686d58fd3da805da53c80c5942d90393/ngram-3.3.2.tar.gz\n",
      "Installing collected packages: ngram\n",
      "  Running setup.py install for ngram: started\n",
      "    Running setup.py install for ngram: finished with status 'done'\n",
      "Successfully installed ngram-3.3.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
